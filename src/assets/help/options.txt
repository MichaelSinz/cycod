USAGE: chatx [...]

OPTIONS

  --system-prompt "PROMPT"        Set the system prompt for the AI model (default: "You are a helpful assistant.")

  --input "LINE1" "LINE2" ...     Provide one or more lines of inputs to the AI model.
  --instruction ...               Alias for --input
  --question ...                  Alias for --input

  --inputs "INPUT1" "INPUT2" ...  Provide one or more inputs, sequentially, to the AI model.
  --instructions ...              Alias for --inputs
  --questions ...                 Alias for --inputs

  --input-chat-history [FILE]     Load chat history from the specified JSONL file.
  --output-chat-history [FILE]    Save chat history to the specified file (default: "chat-history-{time}.jsonl")
  --output-trajectory [FILE]      Save chat history in human readable trajectory format (default: "trajectory-{time}.md")

  --trim-token-target             If LLM payload exceeds this target, message array trimming may take place

  --save-alias ALIAS              Save current options as an alias
  --{ALIAS}                       Use options saved under the specified alias name
  
  --use-copilot                   Use GitHub Copilot (either token or HMAC)
  --use-copilot                   Use GitHub Copilot (with token) as the chat provider
  --use-copilot-hmac              Use GitHub Copilot (with HMAC) as the chat provider
  --use-azure-openai              Use Azure OpenAI API as the chat provider
  --use-openai                    Use OpenAI API as the chat provider
  --use-azure                     Alias for --use-azure-openai
  
  --profile NAME                  Load a named profile from .chatx/profiles/NAME.yaml

SEE ALSO

  chatx help
  chatx help examples
  chatx help provider
